{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "DCGAN_solutions.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVyZZyp5wOw_",
    "colab_type": "text"
   },
   "source": [
    "## Deep Convolutional GAN\n",
    "\n",
    "This exercise is based on the [PyTorch tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html) on DCGAN.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "raAy05AXvQoe",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zpom-KItlrkL",
    "colab_type": "text"
   },
   "source": [
    "## For this exercise it is recommended to use the GPU!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HECwoyeXvZb9",
    "colab_type": "code",
    "outputId": "a813c57a-cc1e-4884-e4c2-c76b3e78bc6d",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576593546701,
     "user_tz": -60,
     "elapsed": 1439,
     "user": {
      "displayName": "Ron van Bree",
      "photoUrl": "",
      "userId": "10574495138637938052"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "\n",
    "use_cuda = True\n",
    "\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "  device = torch.device('cuda')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "\n",
    "device"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 2
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MK8Emkm-lyUg",
    "colab_type": "text"
   },
   "source": [
    "### Load the CIFAR10 dataset\n",
    "\n",
    "Feel free to try other datasets as well, such as the Celeb-A Faces Dataset which is used in the [tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html) on which this exercise is based."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "D_pAwOzsvZhD",
    "colab_type": "code",
    "outputId": "eae609cd-e40d-4caa-e2cb-468523a48dce",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576593562734,
     "user_tz": -60,
     "elapsed": 14153,
     "user": {
      "displayName": "Ron van Bree",
      "photoUrl": "",
      "userId": "10574495138637938052"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    }
   },
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Scale(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data_cifar', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data_cifar', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "c, w, h = 3, 32, 32\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:220: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n",
      "\r0it [00:00, ?it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data_cifar/cifar-10-python.tar.gz\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "170500096it [00:09, 18174836.01it/s]                               \n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Extracting ./data_cifar/cifar-10-python.tar.gz to ./data_cifar\n",
      "Files already downloaded and verified\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkk4g_-hoEoI",
    "colab_type": "text"
   },
   "source": [
    "### Define the Generator and Discriminator models"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SbqyYkSZvZkf",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "n_noise = 100  # Size of the noise vector\n",
    "n_g_channels = 64\n",
    "n_d_channels = 64\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(n_noise, n_g_channels * 8, kernel_size=(4, 4), stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(n_g_channels * 8),\n",
    "            nn.ReLU(),\n",
    "            # state size. (n_g_channels*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(n_g_channels * 8, n_g_channels * 4, kernel_size=(4, 4), stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(n_g_channels * 4),\n",
    "            nn.ReLU(),\n",
    "            # state size. (n_g_channels*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(n_g_channels * 4, n_g_channels * 2, kernel_size=(4, 4), stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(n_g_channels * 2),\n",
    "            nn.ReLU(),\n",
    "            # state size. (n_g_channels*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(n_g_channels * 2,     n_g_channels, kernel_size=(4, 4), stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(n_g_channels),\n",
    "            nn.ReLU(),\n",
    "            # state size. (n_g_channels) x 32 x 32\n",
    "            nn.ConvTranspose2d(    n_g_channels,      c, kernel_size=(4, 4), stride=2, padding=1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. c x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # input is c x 64 x 64\n",
    "            nn.Conv2d(c, n_d_channels, kernel_size=(4, 4), stride=2, padding=1, bias=False),\n",
    "            # nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # state size. (n_d_channels) x 32 x 32\n",
    "            nn.Conv2d(n_d_channels, n_d_channels * 2, kernel_size=(4, 4), stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(n_d_channels * 2),\n",
    "            # nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # state size. (n_d_channels*2) x 16 x 16\n",
    "            nn.Conv2d(n_d_channels * 2, n_d_channels * 4, kernel_size=(4, 4), stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(n_d_channels * 4),\n",
    "            # nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # state size. (n_d_channels*4) x 8 x 8\n",
    "            nn.Conv2d(n_d_channels * 4, n_d_channels * 8, kernel_size=(4, 4), stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(n_d_channels * 8),\n",
    "            # nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # state size. (n_d_channels*8) x 4 x 4\n",
    "            nn.Conv2d(n_d_channels * 8, 1, kernel_size=(4, 4), stride=1, padding=0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output.view(-1, 1)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ep4fjKVYvZeb",
    "colab_type": "code",
    "outputId": "37abff75-6c8e-45c8-c223-e165cf113f88",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576593780186,
     "user_tz": -60,
     "elapsed": 517,
     "user": {
      "displayName": "Ron van Bree",
      "photoUrl": "",
      "userId": "10574495138637938052"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    }
   },
   "source": [
    "\n",
    "G = Generator().to(device)\n",
    "print(G)\n",
    "\n",
    "D = Discriminator().to(device)\n",
    "print(D)"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (model): Sequential(\n",
      "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU()\n",
      "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n",
      "Discriminator(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O7jf8QIXxpIi",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# setup optimizers\n",
    "D_optimizer = optim.Adam(D.parameters(), lr=0.0001)\n",
    "G_optimizer = optim.Adam(G.parameters(), lr=0.0001)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-czNs8qam2_7",
    "colab_type": "text"
   },
   "source": [
    "### Define a function that displays an image tensor"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_flek_8cQuGo",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "inverse_transform = transforms.Compose([transforms.Normalize(mean = [ 0., 0., 0. ], std = [ 1/0.229, 1/0.224, 1/0.225 ]), \n",
    "                                        transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ], std = [ 1., 1., 1. ]),\n",
    "                               ])\n",
    "\n",
    "# Function to show an image tensor\n",
    "def show(X):\n",
    "    X = X.cpu()\n",
    "    X = inverse_transform(X)\n",
    "\n",
    "    plt.imshow(np.transpose(X.numpy(), (1, 2, 0)))\n",
    "    plt.show()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mP0ygGx8m79R",
    "colab_type": "text"
   },
   "source": [
    "### Train the Generator and Discriminator models"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LwLiRs82xpLY",
    "colab_type": "code",
    "outputId": "2bdae540-5009-4338-e7f5-ab7f9b267e9a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576601693910,
     "user_tz": -60,
     "elapsed": 98268,
     "user": {
      "displayName": "Ron van Bree",
      "photoUrl": "",
      "userId": "10574495138637938052"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1Q9DR1I-OigidcaWWOQj6HiYD94mXTiTP"
    }
   },
   "source": [
    "start=time.time()\n",
    "\n",
    "n_show = 16  # Number of generated images that are shown during training\n",
    "\n",
    "fixed_noise = torch.FloatTensor(batch_size, n_noise, 1, 1).normal_(0, 1).to(device)\n",
    "\n",
    "for epoch in range(0,200):\n",
    "\n",
    "  G.train()  # Put the networks in train mode\n",
    "  D.train()\n",
    "  for i, (x_batch, y_batch) in enumerate(trainloader):\n",
    "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n",
    "\n",
    "    ############################\n",
    "    # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "    ###########################\n",
    "    D_optimizer.zero_grad()\n",
    "\n",
    "    # Train on real data\n",
    "    ones_batch = torch.ones(x_batch.size(0), 1).to(device)  # Get a batch of ones indicating these are real images\n",
    "    output_real = D(x_batch)  # Discriminate the images\n",
    "    D_real_loss = criterion(output_real, ones_batch)\n",
    "\n",
    "    # Train on fake data\n",
    "    noise = torch.normal(mean=0, std=1, size=(batch_size, n_noise, 1, 1)).to(device)  # Create random noise as input for G\n",
    "    x_batch_fake = G(noise)  # Create fake images using the generator network\n",
    "    output_fake = D(x_batch_fake.detach())  # Discriminate the images. Detach the tensor for the computation graph so G's parameters won't be optimized here\n",
    "    zero_batch = torch.zeros(x_batch_fake.size(0), 1).to(device)  # Get a batch of zeros indicating these are fake images\n",
    "    D_fake_loss = criterion(output_fake, zero_batch)\n",
    "    \n",
    "    D_loss = D_real_loss + D_fake_loss\n",
    "    D_loss.backward()\n",
    "    D_optimizer.step()\n",
    "\n",
    "    ############################\n",
    "    # (2) Update G network: maximize log(D(G(z)))\n",
    "    ###########################\n",
    "    G_optimizer.zero_grad()\n",
    "\n",
    "    ones_batch = torch.ones(x_batch_fake.size(0), 1).to(device)  # Get a batch of ones indicating these are real images\n",
    "    output_fake = D(x_batch_fake)\n",
    "    G_loss = criterion(output_fake, ones_batch)\n",
    "    G_loss.backward()\n",
    "    G_optimizer.step()\n",
    "\n",
    "    elapsed = time.time() - start  # Keep track of how much time has elapsed\n",
    "\n",
    "    if not i % 20:\n",
    "      print(f'epoch: {epoch}, time: {elapsed:.3f}s, D loss: {D_loss.item():.3f}, G loss: {G_loss.item():.3f}')\n",
    "    if not i % 100:\n",
    "      show(torchvision.utils.make_grid(x_batch_fake[:n_show].detach()))\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Output hidden; open in https://colab.research.google.com to view."
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kYxj6EFExpR9",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yg8NYNH_xpFO",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aVynFOlcvZXl",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}